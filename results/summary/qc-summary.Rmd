---
  html_document:
    toc: true
    highlight: zenburn
    theme: united
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(tidy=TRUE, highlight=TRUE, dev="png",
               cache=TRUE, highlight=TRUE, autodep=TRUE, warning=FALSE, error=FALSE,
               message=FALSE, prompt=TRUE, comment='', fig.cap='', echo=FALSE)
```

# Overview
This is a pilot RNA-seq study looking at gene expression in myeloid dendritic
cells in patients with multiple sclerosis (MS) vs healthy controls.

The total amount of RNA for these samples was low, somewhere in the 50 ng range.

The libraries were prepped and run by the Biopolymers facility, they are 50 bp
paired-end reads.

The goal of this is to examine the quality of the data and determine whether or
not we should sequence more of these libraries. There was a question in particular
about one sample. There was one sample with a large number of reads,
and one question is whether or not that sample can be excluded from further
sequencing runs. Glancing below, that sample is **HC-6**.

This analysis is archived and version controlled [here](https://github.com/hbc/felipe-ms-rnaseq).

```{r qc-setup}
library(ggplot2)
library(reshape)
library(gplots)
library(edgeR)
library(CHBUtils)
library(pheatmap)
project_summary = "../project-summary.csv"
counts_file = "../combined.counts"
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442",
"#0072B2", "#D55E00", "#CC79A7")
summarydata = data.frame(read.table(project_summary, header=TRUE, sep=","), row.names="Name", check.rows=FALSE)
summarydata$Name = rownames(summarydata)
summarydata = summarydata[order(summarydata$Name),]
counts = read.table(counts_file, header=TRUE, row.names="id", check.names=FALSE)
counts = counts[, order(colnames(counts))]
colnames(counts) = gsub(".counts", "", colnames(counts))
# this is a list of all non user-supplied metadata columns that could appear
known_columns = c("Name", "X.GC", "Exonic.Rate", "Sequences.flagged.as.poor.quality",
    "Fragment.Length.Mean", "Intronic.Rate", "Intergenic.Rate",
    "Quality.format", "Duplication.Rate.of.Mapped", "Mapped",
    "rRNA", "Sequence.length", "Transcripts.Detected", "Mean.Per.Base.Cov.",
    "Unique.Starts.Per.Read", "unique_starts_per_read", "Genes.Detected",
    "complexity", "X5.3.bias", "Duplicates.pct", "Duplicates", "Mapped.reads",
    "Median.insert.size", "Mapped.reads.pct", "Total.reads",
    "avg_coverage_per_region")
## some kludging to fix that was had an undetermined sample
summarydata = subset(summarydata, !condition == "")
counts = counts[, colnames(counts) %in% summarydata$Name]
summarydata$condition = factor(summarydata$condition)
summarydata$genes_detected = colSums(counts > 0)
EXTRA_RUNS = 5
summarydata$pairing = c("A", "A", "A", "B", "B", "B", "C", "C", "C",
                       "C", "C", "C", "B", "B", "B", "A", "A", "A")
summarydata$treatment = c("natural", "LPS", "LPS+IL27",
                          "natural", "LPS", "LPS+IL27",
                          "LPS", "LPS+IL27", "natural",
                          "natural", "LPS", "LPS+IL27",
                          "natural", "LPS", "LPS+IL27",
                          "natural", "LPS", "LPS+IL27")
```

```{r heatmap-function}
get_heatmap_fn = function(summarydata) {
    # return the pheatmap function with or without metadata
    metadata = summarydata[, !colnames(summarydata) %in% known_columns, drop=FALSE]
    if(ncol(metadata) == 0) {
       return(pheatmap)
    }
    else {
    # rownames(metadata) = summarydata$Name
    heatmap_fn = function(data, ...) {
        pheatmap(data, annotation=metadata, ...)
    }
    return(heatmap_fn)
}}
heatmap_fn = get_heatmap_fn(summarydata)
```

# Quality control metrics

## Mapped reads
```{r mapped-plot}
ggplot(summarydata, aes(x=Name, y=Mapped)) +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) +
    geom_bar(stat="identity") +
    ylab("mapped reads") + xlab("")
```

We can see that **HC-6** is the sample that has a large number of reads assigned
to it. Worryingly, we can see several samples that have a very low number of
reads mapped. Below we look at how many more times we'd have to sequence
each sample to get to having  25,000,000 reads mapped, a reasonable threshold
for doing gene-level differential expression.

```{r times-mapped-barplot}
summarydata$times = 25000000 / summarydata$Mapped
ggplot(summarydata, aes(x=Name, y=times)) +
    geom_bar(stat='identity') +
    ylab("number of extra runs") + xlab("") +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90))
```

Some of those are very high, so we will filter them out. Any that would
require `r EXTRA_RUNS` more extra runs, we will drop. That drops
`r sum(summarydata$times >= EXTRA_RUNS)`
samples out and see what the distribution looks like in terms of how many times
we'd have to rerun the samples.

```{r mark-poor-samples}
summarydata$keep = summarydata$times < EXTRA_RUNS
```

```{r times-mapped-histogram}
ggplot(subset(summarydata, keep), aes(x=times)) +
    geom_histogram(binwidth=1) +
    ylab("number of samples") + xlab("number of extra runs") +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90))
```

For the samples that are left, we'd have to run on average `r mean(subset(summarydata, times < EXTRA_RUNS)$times)` more runs.

## Genomic mapping rate
```{r mapping-rate-plot}
summarydata$library_problem = ifelse(summarydata$Mapping.Rate < 0.25, "extremely low",
 ifelse(summarydata$Mapping.Rate < 0.60, "low", "okay"))
ggplot(summarydata, aes(x=Name, y=Mapping.Rate, fill=keep)) +
    geom_bar(stat="identity") +
    ylab("mapping rate") + xlab("") +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90))
```

Above we look at the genomic mapping rate. Even for samples that we voted to
keep, some samples have a low mapping rate. Low mapping rates indicate a problem
with the libraries. This mapping rate is to the whole genome, so if the libraries
contain sequence they should be mapping. Libraries with a low mapping rate
indicate problems with the libraries. We should be expecting there to be a
80% or better alignment rate, but most of the samples are below that rate.
This if often due to sequencing an adapter sequence repeatedly. We flagged
samples as "extremely low" with rates < 0.25 and "low" with rates < 0.60.

## rRNA mapping rate
The samples have some more issues than just having a low mapping rate. Many of
the samples have an extremely high rRNA content as well. rRNA is mostly useless
to look at when performing differential expression, so we will just throw those
reads out. For some libraries, that means we will throw out the majority of the
reads that map.

```{r rRNA-rate-plot}
summarydata$times = summarydata$times / summarydata$rRNA_rate
summarydata$keep = summarydata$times < EXTRA_RUNS
ggplot(summarydata, aes(x=Name, y=rRNA_rate, fill=keep)) +
    geom_bar(stat="identity") +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) +
    ylab("rRNA rate") + xlab("")
```

We'll recalculate the number of times we have to sequence, taking into account
the % of reads that align to rRNA. Now we would drop
`r sum(!summarydata$keep)` samples and have to sequence on average
`r mean(subset(summarydata, times < EXTRA_RUNS)$times)` more runs for the samples that
are left.

This is pretty restrictive, so we can loosen it up to 10 more times instead of
`r EXTRA_RUNS`. We'd be getting around 12 million reads a sample doing that,
which is low but maybe something could be done with it.

```{r update-extra-runs}
EXTRA_RUNS=10
summarydata$keep = summarydata$times < EXTRA_RUNS
```

We should also drop the genes which are rRNA related since they will throw off our analyses. We'll
 do that by looking up the biotypes in biomaRt-- while we are there
 we'll also grab the gene symbols so later on we have something easier to look at.

```{r lookup-biomart-stuff}
library(biomaRt)
human = useMart(biomart = "ENSEMBL_MART_ENSEMBL",
                dataset="hsapiens_gene_ensembl",
                host = "jul2015.archive.ensembl.org")
conversions = getBM(attributes=c("ensembl_gene_id", "hgnc_symbol", "gene_biotype"),
                    mart=human)
rrna_biotypes = c("rRNA", "Mt_rRNA", "misc_RNA", "snRNA", "snoRNA",
                    "tRNA", "Mt_tRNA")
rrna_genes = unique(subset(conversions, gene_biotype %in% rrna_biotypes)$ensembl_gene_id)
```

## Exonic mapping rate
```{r exonic-mapping-plot}
ggplot(summarydata, aes(x=Name, y=Exonic.Rate)) +
    geom_bar(stat="identity") +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) +
    ylab("exonic mapping rate") + xlab("")
```
There are some other indications of issues with the libraries. Above is the exonic mapping rate, this is the proportion of reads that map to the genome that map to exons. We're
expecting this to be around 0.7 or higher for a standard RNA-seq experiment,
here it is a little low. This usually indicates some type of minor DNA contamination
in the experiment. With low amounts of total RNA, trace DNA contamination can end up
taking up a larger proportion of the reads that are created, this might be happening
with these libraries. It is a small problem, though, compared to the low mapping
rate and high rRNA contamination.

## Estimated fragment length of paired-end reads
```{r fragment-length-plot}
ggplot(summarydata, aes(x=Name, y=Fragment.Length.Mean)) +
    geom_bar(stat="identity") +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) +
    ylab("fragment length") + xlab("")
```
Above is the plot of the insert size or fragment length, that is the estimated
size of the piece of cDNA that was captured between the adapter sequences. The
insert size could be a little larger; with 50 basepair reads that means the
two ends of the sequence often align with no gap. We'd like there to be a gap
there, pumping up the fragment size to 200 or 250 would be great. Otherwise
we could have just done single-send 100 bp sequencing and achieved the same
result.

## counts by biotype
```{r counts-by-biotype}
df = counts
df$id = rownames(counts)
melted = melt(df)
merged = merge(melted, conversions, by.x="id", by.y="ensembl_gene_id")
colnames(merged) = c("id", "sample", "count", "symbol", "biotype")
merged$sample = factor(merged$sample)
merged = merged[order(merged$sample),]
merged$count = log(merged$count + 1)
ggplot(merged, aes(x=sample, y=count)) + geom_violin() +
    facet_wrap(~biotype) +
    theme_bw(base_size=6) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) + xlab("")
```

We can see most of the counts are in MT_rRNA for each sample. We'll drop
the biotypes that are not either "protein_coding" or "lincRNA".

```{r drop-other}
keep_biotypes = c("protein_coding", "lincRNA")
keep_genes = conversions[conversions$gene_biotype %in% keep_biotypes,]$ensembl_gene_id
counts = counts[rownames(counts) %in% keep_genes,]
```

## Number of genes detected
```{r genes-detected-plot}
dd = data.frame(Name=names(counts), Genes.Detected = colSums(counts > 0))
ggplot(dd, aes(x=Name, y=Genes.Detected)) +
    geom_bar(stat="identity") +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) +
    ylab("genes detected") + xlab("")
```

The above issues with the libraries result in libraries where we don't assay very
many genes. We'd expect there to be around 10-12,000 genes detected (with counts > 0
in at least once sample), but most samples fall far below that as we can see
on the above plot.

## Gene detection saturation
```{r saturation-plot}
dd = data.frame(Mapped=summarydata$Mapped, Genes.Detected = colSums(counts > 0))
ggplot(dd, aes(x=Mapped, y=Genes.Detected)) +
    geom_point() +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) +
    ylab("genes detected") + xlab("reads mapped")
```

Above we can see we're not coming close to saturating the number of genes
detected, which is a rough measure of the complexity of the libraries. More
sequencing is needed.

## Boxplot of log10 counts per gene
```{r boxplot-raw}
melted = melt(counts)
colnames(melted) = c("sample", "count")
melted$sample = factor(melted$sample)
melted = melted[order(melted$sample),]
melted$count = log(melted$count)
ggplot(melted, aes(x=sample, y=count)) + geom_boxplot() +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) + xlab("")
```
Counts per gene is normally not this variable, but we've had some problems
with the libraries. Below we dropped the `r sum(!summarydata$keep)` samples
that are very low quality and normalized them.

## PCA plot from DESeq2
```{r deseq2-pca-before-filtering}
dds = DESeqDataSetFromMatrix(countData=counts, colData=summarydata, design=~condition)
vst = varianceStabilizingTransformation(dds)
plotPCA(vst, intgroup=c("pairing", "condition"))
plotPCA(vst, intgroup=c("treatment", "condition"))
plotPCA(vst, intgroup=c("treatment", "pairing"))
pca = plotPCA(vst, intgroup=c("treatment", "pairing"), return=TRUE)
ggplot(pca, aes(PC1, PC2, color=group, label=name)) + geom_text(size=4) +
    theme_bw() +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90))
```

```{r drop-bad-samples}
summarydata = subset(summarydata, keep)
counts = counts[, summarydata$Name]
```

## Boxplot of log10 TMM-normalized counts per gene
Trimmed mean of M-values (TMM) normalization is described
[here](http://genomebiology.com/2010/11/3/R25)

Robinson, M. D., & Oshlack, A. (2010). A scaling normalization method for differential expression analysis of RNA-seq data. Genome Biology, 11(3). doi:10.1186/gb-2010-11-3-r25

```{r boxplot-normalized}
y = DGEList(counts=counts)
y = calcNormFactors(y)
normalized_counts = cpm(y, normalized.lib.sizes=TRUE)
melted = melt(normalized_counts)
colnames(melted) = c("gene", "sample", "count")
melted$sample = factor(melted$sample)
melted = melted[order(melted$sample),]
melted$count = log(melted$count)
ggplot(melted, aes(x=sample, y=count)) + geom_boxplot() +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) + xlab("")
```

## Density of log10 TMM-normalized counts
```{r density-normalized}
ggplot(melted, aes(x=count, group=sample)) +
    geom_density() +
    theme_bw(base_size=10) +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90)) + xlab("")
```
We can kind of fix the samples doing this, but this is a perfect normalization.

## Correlation (Pearson) heatmap of TMM-normalized counts
```{r pearson-heatmap-normalized}
heatmap_fn(cor(normalized_counts, method="pearson"))
```

## Correlation (Spearman) heatmap of TMM-normalized counts
```{r spearman-heatmap-normalized}
heatmap_fn(cor(normalized_counts, method="spearman"))
```

## MDS plot of TMM-normalized counts
```{r mds-normalized}
mds(normalized_counts, k=length(colnames(normalized_counts)) - 1)
```
Three different methods of clustering the normalized counts doesn't yield
very nice separation between the MS and unaffected cells.

## Nicer PCA plot from DESeq2
```{r deseq2-pca-after-filtering}
dds = DESeqDataSetFromMatrix(countData=counts, colData=summarydata, design=~condition)
vst = varianceStabilizingTransformation(dds)
plotPCA(vst, intgroup=c("pairing", "condition"))
plotPCA(vst, intgroup=c("treatment", "condition"))
pca = plotPCA(vst, intgroup=c("treatment", "pairing"), return=TRUE)
ggplot(pca, aes(PC1, PC2, color=group, label=name)) + geom_text(size=4) +
  scale_colour_manual(values=cbPalette) + theme_bw() +
    theme(panel.grid.major = element_line(size = .5, color = "grey"),
          axis.text.x = element_text(angle=90))
```


## Heatmap of top 30 most expressed genes
```{r top-count-genes, results='asis'}
select = order(rowMeans(counts),decreasing=TRUE)[1:30]
heatmap_fn(counts[select,])
```



## Heatmap by concordance correlation coefficient
http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004075

```{r propcor-heatmap}
propcor = function(x, y) {
    x = log(x + 0.1)
    y = log(y + 0.1)
    num = 2 * cov(x, y)
    denom = var(x) + var(y)
return(num/denom)}

do_propcor = function(x) {
     mat = list()
     for(i in seq_len(ncol(x))) {
         for(j in seq_len(ncol(x))) {
        x2 = x[, i]
        y2 = x[, j]
        mat = c(mat, propcor(x2, y2)) } }
    mat = unlist(mat)
    mat = matrix(mat, ncol(x), ncol(x))
    colnames(mat) = colnames(x)
    rownames(mat) = colnames(x)
    return(mat)}

heatmap_fn(do_propcor(normalized_counts))
```
```{r de-setup}
library(DESeq2)
library(DEGreport)
library(vsn)
design = ~condition
condition = "condition"
```

# Differential expression
```{r deseq2-expression-analysis, results='asis'}
counts <- counts[rowSums(counts>0)>1,]
dds = DESeqDataSetFromMatrix(countData=counts,
    colData=summarydata, design = design)
dds = DESeq(dds)
```

## Effect of variance stabilization

```{r deseq-diagnostics, results='asis'}
par(mfrow=c(1,3))
notAllZero <- (rowSums(counts(dds))>0)
rld <- rlog(dds)
vsd <- varianceStabilizingTransformation(dds)
rlogMat <- assay(rld)
vstMat <- assay(vsd)

meanSdPlot(log2(counts(dds,normalized=TRUE)[notAllZero,] + 1),
           ylim = c(0,2.5))
meanSdPlot(assay(rld[notAllZero,]), ylim = c(0,2.5))
meanSdPlot(assay(vsd[notAllZero,]), ylim = c(0,2.5))
```

## Dispersion estimates

```{r dispersion-estimate}
plotDispEsts(dds)
```

```{r deseq2-handler}
handle_deseq2 = function(dds, summarydata, column) {
  all_combs = combn(levels(summarydata[,column]), 2, simplify=FALSE)
  all_results = list()
  contrast_strings = list()
  for(comb in all_combs) {
    contrast_string = paste(comb, collapse=" vs ")
    contrast = c(column, comb)
    res = results(dds, contrast=contrast)
    res = res[order(res$padj),]
    all_results = c(all_results, res)
    contrast_strings = c(contrast_strings, contrast_string)
  }
  names(all_results) = contrast_strings
  return(all_results)
}
```

## MA-plots

```{r DESeq-output, results='asis'}
all_results = handle_deseq2(dds, summarydata, condition)
len = length(all_results)
nr = ceiling( len / 3 )
nc = ceiling( len / nr )
par(mfrow=c(nr,nc))
for(i in seq(length(all_results))) {
  plotMA(all_results[[i]])
  title(paste("MA plot for contrast", names(all_results)[i]))
}
```

## Volcano-plots

```{r DESeq-volcano}
for(i in seq(length(all_results))) {
  stats = as.data.frame(all_results[[i]][,c(2,6)])
  p = volcano_density_plot(stats, title=names(all_results)[i], lfc.cutoff=1.5)
  print(p)
}
```

## DEGreport

```{r get-groups}
get_groups <- function(d, comp, condition)
{
  g <- unlist(strsplit(comp," "))
  g1 <- d$Name[d[, (names(d)==condition)]==g[1]]
  g2 <- d$Name[d[, (names(d)==condition)]==g[3]]
  list(g1,g2)
}
```

### Pvalues-vs-Mean

We plot some information about how p-values is correlated with the average mean or
the standard desviation. We should see the same distribution for each p-value bin.

```{r DEGreport-M}
plots = list()
scale_factor = round(1/nr * 14)
for(i in seq(length(all_results))) {
  plots[[i]] = degMean(all_results[[i]]$pvalue, rlogMat) +
  theme_bw(base_size = scale_factor) +
  ggtitle(paste0("Pvalues-vs-Mean for ", names(all_results)[i]))
}
do.call(grid.arrange,plots)
```

### Pvalues-vs-Variation

```{r DEGreport-V}
plots = list()
for(i in seq(length(all_results))) {
  plots[[i]] = degVar(all_results[[i]]$pvalue, rlogMat) +
  theme_bw(base_size = scale_factor) +
  ggtitle(paste0("Pvalues-vs-Variation for ", names(all_results)[i]))
}
do.call(grid.arrange,plots)
```

### Mean-vs-Variation
```{r DEGreport-MV}
plots = list()
for(i in seq(length(all_results))) {
  g <- get_groups(summarydata, names(all_results)[i], condition)
  if(length(g[[1]]) < 2 | length(g[[2]]) < 2) {
     next
   }
  plots[[i]] = degMV(g[[1]], g[[2]], all_results[[i]]$pvalue, counts(dds,normalized=TRUE)) +
  theme_bw(base_size = scale_factor) +
  ggtitle(paste0("Mean-vs-Variation for ", names(all_results)[i]))
}
if(length(plots) > 0) {
    do.call(grid.arrange,plots)
}
```

## Differentially expressed genes

```{r DESeq-tables, results='asis'}
for(i in seq(length(all_results))) {
  cat(paste("Lowest adjusted p-value hits for", names(all_results)[i]))
  out_df = as.data.frame(all_results[[i]])
  out_df = merge(out_df, conversions, by.x="row.names", by.y="ensembl_gene_id")
  out_df = out_df[order(out_df$padj),]
  print(knitr::kable(head(out_df)))
  write.table(out_df, file=paste(names(all_results)[i], ".tsv", sep=""),
                         quote=FALSE, sep="\t", row.names=TRUE, col.names=TRUE)
  cat("\n")
}
```

## wrapup
I wouldn't sequence these samples any more for a couple of reasons. The first is
that there are clearly some issues with either the rRNA extraction or the
library creation process and RNA-seq tends to be garbage in and garbage out. The
second reason is that even if we drop some of the really bad samples and if we
try to clean up the data some more, it
doesn't look like there is a suggestion of separation between the samples on whether or not they are MS or control samples. That could be masked due to the poor library quality or it could be that there isn't
any signal there. If we look at the MDS plot we can see that most of the
variation is described by the first principal component, but I
couldn't figure out by looking at the samples what that component was comprised of. If we had more phenotypic information about the patients we could maybe see if they were separating by age or gender or something like that.

Sorry for the not great news. I'm happy to answer any questions you might have.
